---
title: "big function"
author: "Pascal van Luit"
date: "2 February 2020"
output: html_document
---

Other packages that are used:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(lavaan)

set.seed(88)
```

Model to be used for testing:
```{r}
model <- " visual =~ x1 + x2 + x3
           textual =~ x4 + x5 + x6 "
```


## mi_whileloop function
Arguments:
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- min.mi: the minimum MI value for freeing a parameter in the model.
- data: dataset on which the model is fit.

```{r}
mi_whileloop <- function(baseline.model, min.mi = 10, data){
  
  # Saving baseline model as model:
  model <- baseline.model
  
  # Fitting the model to the data:
  fit <- lavaan::cfa(model, data)
  
  # Obtaing MI values:
  MIs <- lavaan::modindices(fit)
  
    # Wrangling the MIs:
    MIs <- MIs %>%
      arrange(-mi) %>% 
      select(lhs, op, rhs, mi)
    
    # Extracting the restricted parameter with the largest MI value:
    largest.mi <- MIs[1, ]
    
    mod <- paste(largest.mi[1, 1], largest.mi[1, 2], largest.mi[1, 3], sep = " ")
  
  while(largest.mi[1, 4] > min.mi) {
    # Update the model:
    model <- model
    
    #  Fitting model to the data
    fit <- lavaan::cfa(model, data)

    # Obtaining MI values:
    MIs <- lavaan::modindices(fit)

      # Wrangling the MIs:
      MIs <- MIs %>%
        arrange(-mi) %>%
        select(lhs, op, rhs, mi)
      
    # Updating largest.mi:
    largest.mi <- MIs[1, ]

    # Extracting the modification to be added to the model:
    mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")

    # Adding the modification to the model:
    model <- paste(model, mod, sep = "
                     ")
      
    print(model)
  }
    
}
```


Testing mi_10_whileloop function:
```{r}
mi_whileloop(baseline.model = model, min.mi = 10, data = HolzingerSwineford1939)
```

Problem: the function adds one modification too much... "visual =~ x5" is not meant to be added. It is indeed the next modification which would be made, but its MI value is < 10.

Are the MI values really above 10 after adding the modifications? Answer: No.
```{r}
mod.model <- " visual =~ x1 + x2 + x3
               textual =~ x4 + x5 + x6
               x2 ~~ x3 "
               #visual =~ x5 "

mod.fit <- lavaan::cfa(mod.model, HolzingerSwineford1939)

modindices(mod.fit) %>% 
  arrange(-mi)
```


################################################################################
################################################################################
################################################################################
################################################################################
################################################################################


## mi_cv function
Arguments;
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- min.mi: minimum modification index value for considering a model modification.
- data: dataset on which the model is fit.
- split: percentage of observations placed in the training set.

```{r}
mi_cv <- function(baseline.model, min.mi, data, split){
  # Adding a column to the dataset to allow a train-validation split:
  data <- data %>% 
           mutate(split = rep(c("train", "test"),
                               times = c(round(split * nrow(data)), round((1 - split) * nrow(data)))))
  
  # Making a separate training set:
  train <- data %>%
            filter(split == "train") %>% 
            select(-split)
  
  test <- data %>%
            filter(split == "test") %>% 
            select(-split)
  
  # Fitting the baseline model to the training set:
  fit.train <- lavaan::cfa(baseline.model, train)
  
    # Fitting the baseline model to the test set to obtain a baseline estimate of chi-square model fit:
    fit.test <- lavaan::cfa(baseline.model, test)
    
      # Baseline values in test set:
      fit.measures.test <- fitmeasures(fit.test)
      
      test.baseline <- c(fit.measures.test["chisq"],
                         fit.measures.test["pvalue"],
                         fit.measures.test["df"])
    
    
    
      # # A matrix to store the baseline values of model fit in test set:
      # test.baseline.mat <- matrix()
      # 
      # # Obtaining the chi-square value, p-value and degrees of freedom:
      # fit.measures.test         <- fitmeasures(fit.test)
      # test.baseline.mat$chisq   <- fit.measures.test["chisq"]
      # test.baseline.mat$pvalue  <- fit.measures.test["pvalue"]
      # test.baseline.mat$df      <- fit.measures.test["df"]
  
  # Obtaining the MIs:
  mi.train <- lavaan::modindices(fit.train)
  
    # Ordering the MIs from largest to smallest:
    mi.train <- mi.train[order(-mi.train$mi), ]
    
    # Taking only the relevant columns:
    mi.train <- mi.train[, 1:4]
    
      # Extracting the first row from those relevant columns:
      lhs <- mi.train[1, 1]
      op  <- mi.train[1, 2]
      rhs <- mi.train[1, 3]
      
      # The first modification to be added to the model:
      mod1 <- paste(lhs, op, rhs, sep = " ")
      
    # Adding the first modification to the model:
      new.model <- paste(baseline.model, mod1, sep = "
                         ")
    
    
    # After adding a modification to the model, the model fit on the test set must be obtained and compared to the previous model fit on the test set. This, to check if there is an improvement
    fit.test.mod <- lavaan::cfa(new.model, test)  
    sum.fit.test.mod <- summary(fit.test.mod)
    
    # Checking the model diagram with the modification:
    # diagram <- semPaths(fit.test.mod, title = FALSE, curvepivot = TRUE)
      
      
        
    # return for checking:
    return(test.baseline)
}
  
```


Testing out function mi_cv:
```{r}
test <- mi_cv(baseline.model = model, data = HolzingerSwineford1939, split = 0.7)

test

```



Things to add:
  - folds
