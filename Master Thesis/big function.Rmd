---
title: "big function"
author: "Pascal van Luit"
date: "2 February 2020"
output: html_document
---

Other packages that are used:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(lavaan)

set.seed(88)
```

Model to be used for testing:
```{r}
model <- " visual =~ x1 + x2 + x3
           textual =~ x4 + x5 + x6 "
```


## mi_whileloop function
Arguments:
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- min.mi: the minimum MI value for freeing a parameter in the model.
- data: dataset on which the model is fit.

```{r}
mi_whileloop <- function(baseline.model, min.mi = 10, data, ...){
  
  # Saving baseline model as model:
  model <- baseline.model
  
  # Fitting the model to the data:
  fit <- lavaan::cfa(model, data)
  
  # Obtaing MI values:
  MIs <- lavaan::modindices(fit)
  
    # Wrangling the MIs:
    MIs <- MIs %>%
      arrange(-mi) %>% 
      select(lhs, op, rhs, mi)
    
    # Extracting the restricted parameter with the largest MI value:
    largest.mi <- MIs[1, ]
    
    mod <- paste(largest.mi[1, 1], largest.mi[1, 2], largest.mi[1, 3], sep = " ")
  
  while(largest.mi[1, 4] > min.mi) {
    

    # Extracting the modification to be added to the model:
    mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")

    # Adding the modification to the model:
    model <- paste(model, mod, sep = "\n")
    
    # Fitting model to the data
    fit <- lavaan::cfa(model, data)

    # Obtaining MI values:
    MIs <- lavaan::modindices(fit)

      # Wrangling the MIs:
      MIs <- MIs %>%
        arrange(-mi) %>%
        select(lhs, op, rhs, mi)
  
    # Updating largest.mi:
    largest.mi <- MIs[1, ]
    
    print(model)
  }
    
}
```


Testing mi_10_whileloop function:
```{r}
mi_whileloop(baseline.model = model, min.mi = 10, data = HolzingerSwineford1939)
```


Are the MI values really above 10 after adding the modifications? Answer: No.
```{r}
mod.model <- " visual =~ x1 + x2 + x3
               textual =~ x4 + x5 + x6
               x2 ~~ x3 "
               #visual =~ x5 "

mod.fit <- lavaan::cfa(mod.model, HolzingerSwineford1939)

modindices(mod.fit) %>% 
  arrange(-mi)
```


################################################################################
################################################################################
################################################################################
################################################################################
################################################################################


## mi_cv function
Arguments;
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- min.mi: minimum modification index value for considering a model modification.
- data: dataset on which the model is fit.
- split: percentage of observations placed in the training set.

```{r}
mi_cv <- function(baseline.model, min.mi, data, split, ...){
  
  # Adding a column to the dataset to allow a train-validation split:
  data <- data %>% 
           mutate(split = rep(c("train", "test"),
                               times = c(round(split * nrow(data)), round((1 - split) * nrow(data)))))
  
  # Making a separate training set:
  train <- data %>%
            filter(split == "train") %>% 
            select(-split)
  
  test <- data %>%
            filter(split == "test") %>% 
            select(-split)
  
  # Saving baseline model as model:
  model <- baseline.model
  
  # Fitting the baseline model to the training set:
  fit.train <- lavaan::cfa(model, train, ...)
  
  # Fitting the baseline model to the test set to obtain a baseline estimate of chi-square model fit:
  fit.test <- lavaan::cfa(baseline.model, test, ...)
    
      # Saving the baseline values in test set:
      # - these values are to be used to assess if there is an improvement in fit in the test set when a modification is added.
      fit.measures.test <- fitmeasures(fit.test)
      
      test.baseline <- data.frame(test.chisq.baseline  = fit.measures.test["chisq"],
                                  test.pvalue = fit.measures.test["pvalue"],
                                  test.df     = fit.measures.test["df"])
    
  ###################
  # WHILE FUNCTTION #
  ###################
  while(mod.fit.measures.test$mod.test.chisq < test.chisq.baseline && test.pvalue < 0.5 && test.df >= 0){
    
    # Update the model:
    model <- model
    
    # Fitting the model to the training data
    fit.train <- lavaan::cfa(model, train)
    
      # Fitting the model to the test data:
      fit.test <- lavaan::cfa(model, test)
      
      # Obtaining baseline values of model fit in the test set:
      fit.measures.test <- lavaan::fitmeasures(fit.test)
      test.baseline <- data.frame(test.chisq.baseline = fit.measures.test["chisq"],
                                  test.pvalue = fit.measures.test["pvalue"],
                                  test.df     = fit.measures.test["df"])
    
    # Obtaining MI values in the training set:
    mi.train <- lavaan::modindices(fit.train)
    
    # Wrangling the MIs:
    mi.train <- mi.train %>% 
      arrange(-mi) %>% 
      select(lhs, op, rhs, mi)
    
    # Extracting the modification to be added to the model:
    mod.train <- paste(mi.train[1, 1], mi.train[1, 2], mi.train[1, 3], sep = " ")
    
    # Adding the modification to the model:
    mod.model <- paste(model, mod.train, sep = "\n")
    
      # Fitting the modified model to the test set:
      mod.fit.test <- lavaan::cfa(mod.model, test)
    
      # Obtaining new model fit values to compare to the baseline values:
      mod.fit.measures.test <- lavaan::fitmeasures(mod.fit.test)
      mod.fit.measures.test <- data.frame(mod.test.chisq  = mod.fit.measures.test["chisq"],
                                          mod.test.pvalue = mod.fit.measures.test["pvalue"],
                                          mod.test.df     = mod.fit.measures.test["df"])
    
    print(model)
    
  }
      
      
# This below was an attempt at doing it another way (without using a while loop):
      
  # # Obtaining the MIs:
  # mi.train <- lavaan::modindices(fit.train)
  #   
  #   # Taking only the relevant columns:
  #   mi.train <- mi.train %>%
  #     arrange(-mi) %>% 
  #     select(lhs, op, rhs, mi)
  #   
  #     # Extracting the first row from those relevant columns:
  #     lhs <- mi.train[1, 1]
  #     op  <- mi.train[1, 2]
  #     rhs <- mi.train[1, 3]
  #     
  #     # The first modification to be added to the model:
  #     mod1 <- paste(lhs, op, rhs, sep = " ")
  #     
  #   # Adding the first modification to the model:
  #     new.model <- paste(baseline.model, mod1, sep = "
  #                        ")
  #   
  #   
  #   # After adding a modification to the model, the model fit on the test set must be obtained and compared to the previous model fit on the test set. This, to check if there is an improvement
  #   fit.test.mod <- lavaan::cfa(new.model, test)  
  #   # sum.fit.test.mod <- summary(fit.test.mod)
  #   
  #   # Checking the model diagram with the modification:
  #   # diagram <- semPaths(fit.test.mod, title = FALSE, curvepivot = TRUE)
  #     
  #     
  #       
  #   # return for checking:
  #   return(test.baseline)
}
  
```


Testing out function mi_cv:
```{r}
test <- mi_cv(baseline.model = model, data = HolzingerSwineford1939, split = 0.7)

test
```



Things to add:
  - folds
  - minimum MI value
