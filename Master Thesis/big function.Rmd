---
title: "big function"
author: "Pascal van Luit"
date: "2 February 2020"
output: html_document
---

Other packages that are used:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(lavaan)

set.seed(88)
```

Model to be used for testing:
```{r}
model <- " visual =~ x1 + x2 + x3
           textual =~ x4 + x5 + x6 "
```


## mi_whileloop function
Arguments:
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- min.mi: the minimum MI value for freeing a parameter in the model.
- data: dataset on which the model is fit.

```{r}
mi_whileloop <- function(baseline.model, min.mi = 10, data, ...){
  
  # Saving baseline model as model:
  model <- baseline.model
  
  # Fitting the model to the data:
  fit <- lavaan::cfa(model, data)
  
  # Obtaing MI values:
  MIs <- lavaan::modindices(fit)
  
    # Wrangling the MIs:
    MIs <- MIs %>%
      arrange(-mi) %>% 
      select(lhs, op, rhs, mi)
    
    # Extracting the restricted parameter with the largest MI value:
    largest.mi <- MIs[1, ]
    
    # Specifying a modification to be added to the model:
    mod <- paste(largest.mi[1, 1], largest.mi[1, 2], largest.mi[1, 3], sep = " ")

## Starting the while loop:  
  while(largest.mi[1, 4] > min.mi) {
    
    # Extracting the modification to be added to the model:
    mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")

    # Adding the modification to the model:
    model <- paste(model, mod, sep = "\n")
    
    # Fitting model to the data
    fit <- lavaan::cfa(model, data)

    # Obtaining MI values:
    MIs <- lavaan::modindices(fit)

      # Wrangling the MIs:
      MIs <- MIs %>%
        arrange(-mi) %>%
        select(lhs, op, rhs, mi)
  
    # Updating largest.mi:
    largest.mi <- MIs[1, ]
    
    print(model)
  }
 
  # return the baseline model as well:
  return(baseline.model)  
       
}
```


Testing mi_whileloop function:
```{r}
mi_whileloop(baseline.model = model, min.mi = 10, data = HolzingerSwineford1939)
```


################################################################################
################################################################################
################################################################################
################################################################################
################################################################################


## mi_cv function
Arguments;
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- min.mi: minimum modification index value for considering a model modification.
- data: dataset on which the model is fit.
- split: percentage of observations placed in the training set.

```{r}
mi_cv <- function(baseline.model, data, split, ...){
  
  # Adding a column to the dataset to allow a train-validation split:
  data <- data %>% 
    mutate(split = rep(c("train", "test"),
                       times = c(round(split * nrow(data)), round((1 - split) * nrow(data)))))
  
  # Making a separate training set:
  train <- data %>%
    filter(split == "train") %>% 
    select(-split)
  
  # Making a separate test set:
  test <- data %>%
    filter(split == "test") %>% 
    select(-split)
  
  # Saving baseline model as model:
  model <- baseline.model
  
  ## Fitting the baseline model to the training set:
  fit.train <- lavaan::cfa(model, train, ...)
  
  # Obtaining MI values according to the training set:
  MIs <- lavaan::modindices(fit.train)
  
  # Wrangling the MIs:
  MIs <- MIs %>%
    arrange(-mi) %>% 
    select(lhs, op, rhs, mi)
  
  # Specifying a modification to be added to the model:
  mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")
  
  ## Fitting the baseline model to the test set:
  fit.test.1 <- lavaan::cfa(model, test, ...)
  
  
  # Adding a modification to the model:
  mod.model <- paste(model, mod, sep = "\n")
  
  # Find the fit of the modified model on the test set:
  fit.test.2 <- lavaan::cfa(mod.model, test, ...)
  
  # Seeing whether this improves the fit:
  chisq.diff <- lavaan::lavTestLRT(fit.test.1, fit.test.2)
  
  # Assigning whether significantly better or not:
  ifelse(chisq.diff$`Pr(>Chisq)`[2] < .05, sign <- TRUE, sign <- FALSE)
  
  ###################
  # WHILE FUNCTTION #
  ###################
  while(sign == TRUE){
    
    # Extracting a modification to be added to the model:
    mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")
    
    # Adding modification to the model:
    model <- paste(model, mod, sep = "\n")
    
    # Fitting the model to the test set:
    fit.test.2 <- lavaan::cfa(model, test)
    
    # Checking the chisq.diff in the test set:
    chisq.diff <- lavaan::lavTestLRT(fit.test.1, fit.test.2)
    
    # If function to update sign:
    ifelse(chisq.diff$`Pr(>Chisq)`[2] < .05,
           sign <- TRUE,
           sign <- FALSE)
    
    # chisq.diff <- chisq.diff$`Pr(>Chisq)`
    
    # Fitting the model to the train set:
    fit.train <- lavaan::cfa(model, train)
    
    # Obtaining new MI values:
    MIs <- lavaan::modindices(fit.train)
    
    # Wrangling the MIs
    MIs <- MIs %>%
      arrange(-mi) %>% 
      select(lhs, op, rhs, mi)
    
    # Print the final model
    print(model)
    
  }
  
  # Return the baseline model as well:
  return(baseline.model)
  
}
```


Testing out function mi_cv:
```{r}
test <- mi_cv(baseline.model = model, data = HolzingerSwineford1939, split = 0.7)

test
```

Manually checking the mi_cv function:
```{r}
data <- HolzingerSwineford1939

# Setting up the split:

  # Adding a column to the dataset to allow a train-validation split:
  data <- data %>% 
    mutate(split = rep(c("train", "test"),
                       times = c(round(0.7 * nrow(data)), round((1 - 0.7) * nrow(data)))))
  
  # Making a separate training set:
  train <- data %>%
    filter(split == "train") %>% 
    select(-split)
  
  test <- data %>%
    filter(split == "test") %>% 
    select(-split)
  
# Split set up done.


# Fitting to train and test. Using train to find a mod to be added:
  
  # Fitting the baseline model to the training set:
  fit.train <- lavaan::cfa(model, train)
  
  # Fitting it to the test set:
  fit.test.1 <- lavaan::cfa(model, test)

  # Finding MIs to determine which mod to add to the model:
  mi.train <- lavaan::modindices(fit.train)

  mi.train %>% 
    arrange(-mi)

  # Adding the mod to the model
  new.model <- " visual =~ x1 + x2 + x3
                textual =~ x4 + x5 + x6 
                visual =~ x5 "

  # Fitting the new model to the test set:
  fit.test.2 <- lavaan::cfa(new.model, test)
  
# Fits done.
  
# Finding if the mod improves fit in the test set to determine if the mod should be accepted or not:

diff <- lavaan::lavTestLRT(fit.test.2, fit.test.1)

diff
# diff is found to be insignificant, so the modification should not be added. The chisq stat stays almost the same...
```


Looking at the chi-square difference test:
```{r}
HS.model <- '
    visual  =~ x1 + x2 + x3
    textual =~ x4 + x5 + x6
    speed   =~ x7 + x8 + x9
'
fit1 <- lavaan::cfa(HS.model, data = HolzingerSwineford1939)
fit0 <- lavaan::cfa(HS.model, data = HolzingerSwineford1939, orthogonal = TRUE)

difftest <- lavTestLRT(fit1, fit0)

difftest <- difftest$`Pr(>Chisq)`
difftest[2]
```



Things to add:
  - folds
  - minimum MI value
