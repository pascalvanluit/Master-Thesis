---
title: "big function"
author: "Pascal van Luit"
date: "2 February 2020"
output: html_document
---

Set up:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(lavaan)

set.seed(88)

# Model to be used for testing:
model <- " visual =~ x1 + x2 + x3
           textual =~ x4 + x5 + x6 "
```


## mi_whileloop function
Arguments:
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- min.mi: the minimum MI value for freeing a parameter in the model.
- data: dataset on which the model is fit.

```{r}
mi_whileloop <- function(baseline.model, min.mi = 10, data, ...){
  
  # Saving baseline model as model:
  model <- baseline.model
  
  # Fitting the model to the data:
  fit <- lavaan::cfa(model, data)
  
  # Obtaing MI values:
  MIs <- lavaan::modindices(fit)
  
    # Wrangling the MIs:
    MIs <- MIs %>%
      arrange(-mi) %>% 
      select(lhs, op, rhs, mi)
    
    # Extracting the restricted parameter with the largest MI value:
    largest.mi <- MIs[1, ]
    
    # Specifying a modification to be added to the model:
    mod <- paste(largest.mi[1, 1], largest.mi[1, 2], largest.mi[1, 3], sep = " ")

## Starting the while loop:  
  while(largest.mi[1, 4] > min.mi) {
    
    # Extracting the modification to be added to the model:
    mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")

    # Adding the modification to the model:
    model <- paste(model, mod, sep = "\n")
    
    # Fitting model to the data
    fit <- lavaan::cfa(model, data)

    # Obtaining MI values:
    MIs <- lavaan::modindices(fit)

      # Wrangling the MIs:
      MIs <- MIs %>%
        arrange(-mi) %>%
        select(lhs, op, rhs, mi)
  
    # Updating largest.mi:
    largest.mi <- MIs[1, ]
    
    # Name the model:
    print(model)
    
  }
 
  # return the baseline model as well (with a label):
  names(baseline.model) <- c("Baseline Model")
  return(baseline.model)  
       
}
```


Testing mi_whileloop function:
```{r}
mi_whileloop(baseline.model = model, min.mi = 5, data = HolzingerSwineford1939)
```


################################################################################
################################################################################
################################################################################
################################################################################
################################################################################


## mi_cv function
Arguments;
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- min.mi: minimum modification index value for considering a model modification.
- data: dataset on which the model is fit.
- split: percentage of observations placed in the training set.

```{r}
mi_cv <- function(baseline.model, data, split, ...){
  
  # Adding a column to the dataset to allow a train-validation split:
  data <- data %>% 
    mutate(split = rep(c("train", "test"),
                       times = c(round(split * nrow(data)), round((1 - split) * nrow(data)))))
  
  # Making a separate training set:
  train <- data %>%
    filter(split == "train") %>% 
    select(-split)
  
  # Making a separate test set:
  test <- data %>%
    filter(split == "test") %>% 
    select(-split)
  
  # Saving baseline model as model:
  model <- baseline.model
  
  ## Fitting the baseline model to the training set:
  fit.train <- lavaan::cfa(model, train, ...)
  
  # Obtaining MI values according to the training set:
  MIs <- lavaan::modindices(fit.train)
  
  # Wrangling the MIs:
  MIs <- MIs %>%
    arrange(-mi) %>% 
    select(lhs, op, rhs, mi)
  
  # Specifying a modification to be added to the model:
  mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")
  
  ## Fitting the baseline model to the test set:
  fit.test.1 <- lavaan::cfa(model, test, ...)
  
  
  # Adding a modification to the model:
  mod.model <- paste(model, mod, sep = "\n")
  
  # Find the fit of the modified model on the test set:
  fit.test.2 <- lavaan::cfa(mod.model, test, ...)
  
  # Seeing whether this improves the fit:
  chisq.diff <- lavaan::lavTestLRT(fit.test.1, fit.test.2)
  
  # Assigning whether significantly better or not:
  ifelse(chisq.diff$`Pr(>Chisq)`[2] < .05, sign <- TRUE, sign <- FALSE)
  
  ###################
  # WHILE FUNCTTION #
  ###################
  while(sign == TRUE){
    
    # Extracting a modification to be added to the model:
    mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")
    
    # Adding modification to the model:
    model <- paste(model, mod, sep = "\n")
    
    # Fitting the model to the test set:
    fit.test.2 <- lavaan::cfa(model, test)
    
    # Checking the chisq.diff in the test set:
    chisq.diff <- lavaan::lavTestLRT(fit.test.1, fit.test.2)
    
    # If function to update sign:
    ifelse(chisq.diff$`Pr(>Chisq)`[2] < .05,
           sign <- TRUE,
           sign <- FALSE)
    
    # Fitting the model to the train set:
    fit.train <- lavaan::cfa(model, train)
    
    # Obtaining new MI values:
    MIs <- lavaan::modindices(fit.train)
    
    # Wrangling the MIs
    MIs <- MIs %>%
      arrange(-mi) %>% 
      select(lhs, op, rhs, mi)
    
    # Print the final model
    print(model)
    
  }
  
  # Return the baseline model as well (with a label):
  names(baseline.model) <- c("Baseline Model")
  
  return(baseline.model)
  
}
```


Testing out function mi_cv:
```{r}
test <- mi_cv(baseline.model = model, data = HolzingerSwineford1939, split = 0.7)

test
```

Manually checking the mi_cv function:
```{r}
data <- HolzingerSwineford1939

# Setting up the split:

  # Adding a column to the dataset to allow a train-validation split:
  data <- data %>% 
    mutate(split = rep(c("train", "test"),
                       times = c(round(0.7 * nrow(data)), round((1 - 0.7) * nrow(data)))))
  
  # Making a separate training set:
  train <- data %>%
    filter(split == "train") %>% 
    select(-split)
  
  test <- data %>%
    filter(split == "test") %>% 
    select(-split)
  
# Split set up done.


# Fitting to train and test. Using train to find a mod to be added:
  
  # Fitting the baseline model to the training set:
  fit.train <- lavaan::cfa(model, train)
  
  # Fitting it to the test set:
  fit.test.1 <- lavaan::cfa(model, test)

  # Finding MIs to determine which mod to add to the model:
  mi.train <- lavaan::modindices(fit.train)

  mi.train %>% 
    arrange(-mi)

  # Adding the mod to the model
  new.model <- " visual =~ x1 + x2 + x3
                textual =~ x4 + x5 + x6 
                visual =~ x5 "

  # Fitting the new model to the test set:
  fit.test.2 <- lavaan::cfa(new.model, test)
  
# Fits done.
  
# Finding if the mod improves fit in the test set to determine if the mod should be accepted or not:

diff <- lavaan::lavTestLRT(fit.test.2, fit.test.1)

diff
# diff is found to be insignificant, so the modification should not be added. The chisq stat stays almost the same...
```


Looking at the chi-square difference test:
```{r}
HS.model <- '
    visual  =~ x1 + x2 + x3
    textual =~ x4 + x5 + x6
    speed   =~ x7 + x8 + x9
'
fit1 <- lavaan::cfa(HS.model, data = HolzingerSwineford1939)
fit0 <- lavaan::cfa(HS.model, data = HolzingerSwineford1939, orthogonal = TRUE)

difftest <- lavTestLRT(fit1, fit0)

difftest <- difftest$`Pr(>Chisq)`
difftest[2]
```

## mi_cv_kfold function
Arguments:
- baseline.model: the baseline sem model which is defined in lavaan syntax.
- data: dataset on which the model is fit.
- k: number of folds.
```{r}
mi_cv_kfold <- function(baseline.model, data, k = 5){
  
  # Saving the baseline.model as model:
  model <- baseline.model
  
## Setting up the dataset to be split into k folds:
  
    # Adding a column with assignment for each observation:
    n.obs      <- nrow(data)
    select.vec <- rep(1:k, length.out = n.obs)
    data.split <- data %>% mutate(fold = sample(select.vec))
    
    # Create output vector for in the validation set:
    fit.valids <- rep(0, k)

  ############
  # FOR LOOP #
  ############
        
## Fitting the data to a the different training sets:
  for (i in 1:k) {
    
    # Splitting the data in train and validation set
    train <- data.split %>% filter(fold != i)
    valid <- data.split %>% filter(fold == i)
    
    # Fitting the baseline model on the training set:
    fit.train.i <- lavaan::cfa(model, train)
    
    # Finding which modification to add based on the training portion:
    MIs <- lavaan::modindices(fit.train.i)
    
      # Wrangling the MIs:
      MIs <- MIs %>% arrange(-mi) %>% select(lhs, op, rhs, mi)
      
    # Specifying a modification to be added to the model:
    mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")
    
    # Fitting the baseline model to the validation set:
    fit.valid.1.i <- lavaan::cfa(model, valid)
    
    # Adding a modification to the model:
    mod.model <- paste(model, mod, sep = "\n")
    
    # Find the fit of the modified model on the validation set:
    fit.valid.2.i <- lavaan::cfa(mod.model, valid)
    
    # Seeing whether this improves the fit:
    chisq.diff.i <- lavaan::lavTestLRT(fit.valid.1.i, fit.valid.2.i)
    
    # Assigning whether fit is significantly better or not:
    ifelse(chisq.diff.i$`Pr(>Chisq)`[2] < .05, sign <- TRUE, sign <- FALSE)
    
    # Finding the mean p-value:
    mean.chisq.diff <- mean(chisq.diff.i)
    
    # Creating chisq.diff object:
    # mean.chisq.diff <- list(`Pr(>Chisq)` = 0)
    
  ###################
  # WHILE FUNCTTION #
  ###################
  while (mean.chisq.diff$`Pr(>Chisq)` < .05) {
    
    # Extracting a modification to be added to the model:
    mod <- paste(MIs[1, 1], MIs[1, 2], MIs[1, 3], sep = " ")
    
    # Adding a modification to the model:
    model <- paste(model, mod, sep = "\n")
    
    # Fitting the model to the validation set:
    fit.valid.2.i <- lavaan::cfa(model, valid)
    
    # Obtaining chisq.diffs and finding the mean:
    fit.valids[i] <- lavaan::lavTestLRT(fit.valid.1.i, fit.valid.2.i)
    mean.chisq.diff <- mean(fit.valids[i])
    
    # Fitting the model to the training set:
    fit.train <- lavaan::cfa(model, train)
    
    # Obtaining new MI values:
    MIs <- lavaan::modindices(fit.train)
    
      # Wrangling the MIs:
      MIs <- MIs %>% arrange(-mi) %>% select(lhs, op, rhs, mi)
      
    # Print the final model:
    print(model)
    
  } 
  
    
    # # Adding the modification to the model:
    # model <- paste(model, mod, sep = "\n")
    # 
    # # Fitting the modified model on the valid set:
    # fit_valid_2 <- lavaan::cfa(model, valid)
    # 
    # # Checking the chisq.diff in the validation set:
    # chisq.diff[i] <- lavaan::lavTestLRT(fit_valid_1_i, fit_valid_2)
    # 
    # # Getting a mean of the chisq.diff's
    # mean.chisq.diff <- mean(chisq.diff[i])
    
    # # Calculate the model fit in the validation set:
    # fit_measures_valids <- lavaan::fitmeasures(fit_valid, c("chisq", "df", "pvalue"))
    # 
    # # Find the average of the fits in the validation sets:
    # fit_valids[i] <- mean(fit_measures_valids)
    # 
    # #Print the final model:
    # print(model)
    
  }
    
  # return()
    
}
```

Testing out the mi_cv_kfold function:
```{r}
mi_cv_kfold(baseline.model = model, data = HolzingerSwineford1939, k = 5)
```




Things to add:
  - folds
  - minimum MI value
