---
title: "Beginnings"
author: "Pascal van Luit"
date: "29 January 2020"
output: html_document
---

Loading packages that are likely to be relevant:
```{r}
library(lavaan)
library(sem)
library(semtree)
library(semPlot)
library(tidyverse)

set.seed(88)
```

Model that will be experimented with:
```{r}
model <- " visual =~ x1 + x2 + x3
           textual =~ x4 + x5 + x6 "
# model_add <- " visual =~ x5 "

# final_model <- c(model, model_add)

fit <-lavaan:::cfa(model, HolzingerSwineford1939)

fit.measures <- fitmeasures(fit)
      
baseline <- data.frame(chisq  = fit.measures["chisq"],
                       pvalue = fit.measures["pvalue"],
                       df     = fit.measures["df"])


# test.baseline <- fitmeasures(fit) %>% 
#         select(chisq, pvalue, df)
# test.baseline

# mat <- matrix()
# 
# mat$chi.square.test   <- fits["chisq"]
# mat$p.value.test      <- fits["pvalue"]
# mat$df           <- fits["df"]
# 
# mat
# summary(fit)

# baseline

# partable(fit)
```

Checking the diagram
```{r}
semPaths(fit, "std", "est", title = FALSE, curvepivot = TRUE)
```

Extracting modification indices from model:
```{r}
mi <- modindices(fit)
```

extracting mi values higher than ...:
```{r}
mi_10 <- mi %>% 
  filter(mi > 10)

mi_3.84 <- mi %>% 
  filter(mi > 3.84)

mi_all <- mi

# mi_cv <- 
```

Looking into using cross-validation in the HS dataset:
Starting with a training-test-split
```{r}
HS <- HolzingerSwineford1939
# There are 301 observations. Let's use a 70 - 30 split. 211 train, 90 test.
HS <- HS %>% 
  mutate(split = rep(c("train", "test"), times = c(211, 90)))

trainHS <- HS %>% 
  filter(split == "train") %>% 
  select(-split)

testHS <- HS %>% 
  filter(split == "test") %>% 
  select(-split)
```

Making a model with the training set:
```{r}
fit_train <- lavaan::cfa(model, trainHS)
# summary(fit_train, standardized = TRUE)

obj <- lavTestLRT(fit, fit_train)
obj
obj$`Pr(>Chisq)`
```
Chi-square = 24.581 (p = 0.002)

Getting the MI's
```{r}
mi_train <- modindices(fit_train)
```

Fitting the model to the test set to find a "baseline" chi-square model fit statistic. The idea is that this baseline is used so that the effect of subsequent changes to the model on the chi-square value can be compared. If the fit worsens in the test set, then there is a suggestion that the model is starting to overfit on the training set.

So, let's see, how does one find model fit on a set of observations which is not used to make the model...
```{r}
# Ah, you actually do the same thing as before:
fit_test_baseline <- lavaan::cfa(model, testHS)
summary(fit_test_baseline, standardized = TRUE)
```

Chi-square is 4.757

Ok, now that we have a baseline chi-square statistic of the model fit in the test set we have something compare a new model fit value to.

So, we can start making some modifications to the model based on modification indices.
```{r}
mi_train_max <- mi_train[order(-mi_train$mi),]

head(mi_train_max)
```

The mi values of the training data suggest that adding "visual =~ x5" would improve model fit. So let's add it.

```{r}
new_model_one <- " visual =~ x1 + x2 + x3 + x5
                   textual =~ x4 + x5 + x6 "

fit_train_one <- lavaan::cfa(new_model_one, trainHS)

semPaths(fit_train_one)

#summary(fit_train_one, standardized = TRUE)

```

New chi-square value is 13.308 (p = 0.065)

Let's see if this modification also improves model fit in the test set:
```{r}
fit_test_one <- lavaan::cfa(new_model_one, testHS)

summary(fit_test_one)
```

The new chi-square value is 4.727 (p = 0.693)

How to extract values from fit summary?
Namely: Chi-square value and p-value
```{r}
summary <- summary(fit)

fit
summary

summary$PE
```








