---
title: "Beginnings"
author: "Pascal van Luit"
date: "29 January 2020"
output: html_document
---

Loading packages that are likely to be relevant:
```{r warning=FALSE}
library(lavaan)
library(sem)
library(semtree)
library(semPlot)
library(tidyverse)

set.seed(88)
```

Model that will be experimented with:
```{r}
model <- " visual =~ x1 + x2 + x3
           textual =~ x4 + x5 + x6 "
# model_add <- " visual =~ x5 "
model.2 <- " visual =~ x1 + x2 + x3
             textual =~ x4 + x5 + x6 
             visual =~ x5 "

model.3 <- " visual =~ x1 + x2 + x3
             textual =~ x4 + x5 + x6 
             visual =~ x4 "

fit <-lavaan:::cfa(model, HolzingerSwineford1939)
fit.2 <- lavaan::cfa(model.2, HolzingerSwineford1939)
fit.3 <- lavaan::cfa(model.3, HolzingerSwineford1939)

diff.1 <- lavaan::lavTestLRT(fit.2, fit)
diff.2 <- lavaan::lavTestLRT(fit.3, fit)

mean(diff.1$`Pr(>Chisq)`, diff.2$`Pr(>Chisq)`)

# sum <- summary(fit)
# fitm <- fitmeasures(fit, c("chisq", "df", "pvalue"))
# 
# fitm["df"]
# partable(fit)
```

Checking the diagram
```{r}
semPaths(fit, "std", "est", title = FALSE, curvepivot = TRUE)
```

Extracting modification indices from model:
```{r}
mi <- modindices(fit)
```

extracting mi values higher than ...:
```{r}
mi_10 <- mi %>% 
  filter(mi > 10)

mi_3.84 <- mi %>% 
  filter(mi > 3.84)

mi_all <- mi

# mi_cv <- 
```

Looking into using cross-validation in the HS dataset:
Starting with a training-test-split
```{r}
HS <- HolzingerSwineford1939
# There are 301 observations. Let's use a 70 - 30 split. 211 train, 90 test.
HS <- HS %>% 
  mutate(split = rep(c("train", "test"), times = c(211, 90)))

trainHS <- HS %>% 
  filter(split == "train") %>% 
  select(-split)

testHS <- HS %>% 
  filter(split == "test") %>% 
  select(-split)
```

Making a model with the training set:
```{r}
fit_train <- lavaan::cfa(model, trainHS)
sum <- summary(fit_train)

sum$PE$est

obj <- lavTestLRT(fit, fit_train)
obj
obj$`Pr(>Chisq)`
```
Chi-square = 24.581 (p = 0.002)

Getting the MI's
```{r}
mi_train <- modindices(fit_train)
```

Fitting the model to the test set to find a "baseline" chi-square model fit statistic. The idea is that this baseline is used so that the effect of subsequent changes to the model on the chi-square value can be compared. If the fit worsens in the test set, then there is a suggestion that the model is starting to overfit on the training set.

So, let's see, how does one find model fit on a set of observations which is not used to make the model...
```{r}
# Ah, you actually do the same thing as before:
fit_test_baseline <- lavaan::cfa(model, testHS)
summary(fit_test_baseline, standardized = TRUE)
```

Chi-square is 4.757

Ok, now that we have a baseline chi-square statistic of the model fit in the test set we have something compare a new model fit value to.

So, we can start making some modifications to the model based on modification indices.
```{r}
mi_train_max <- mi_train[order(-mi_train$mi),]

head(mi_train_max)
```

The mi values of the training data suggest that adding "visual =~ x5" would improve model fit. So let's add it.

```{r}
new_model_one <- " visual =~ x1 + x2 + x3 + x5
                   textual =~ x4 + x5 + x6 "

fit_train_one <- lavaan::cfa(new_model_one, trainHS)

semPaths(fit_train_one)

# Trying to fit an empty model:
empty_model <- " "
fit_train_empty <- lavaan::cfa(empty_model, trainHS)
summary(fit_train_empty)
#summary(fit_train_one, standardized = TRUE)

```

New chi-square value is 13.308 (p = 0.065)

Let's see if this modification also improves model fit in the test set:
```{r}
fit_test_one <- lavaan::cfa(new_model_one, testHS)

summary(fit_test_one)
```

The new chi-square value is 4.727 (p = 0.693)

How to extract values from fit summary?
Namely: Chi-square value and p-value
```{r}
summary <- summary(fit)

fit
summary

summary$PE
```

###
Finding the fit* of a model on the test set.
*The model is not fit on the set, instead the parameter values found according to the training set are preserved.
```{r}
HS <- HolzingerSwineford1939
# There are 301 observations. Let's use a 70 - 30 split. 211 train, 90 test.
HS <- HS %>% 
  mutate(split = rep(c("train", "test"), times = c(211, 90)))

trainHS <- HS %>% 
  filter(split == "train") %>% 
  select(-split)

testHS <- HS %>% 
  filter(split == "test") %>% 
  select(-split)

model <- " visual =~ x1 + x2 + x3
           textual =~ x4 + x5 + x6 "


fit.train <- lavaan::cfa(model, trainHS)
summary(fit.train)

fit.test <- lavaan::lavaan(model = model, data = testHS,
                           auto.fix.first = TRUE, auto.var = TRUE,
                           do.fit = FALSE, start = fit.train,
                           test = "standard",
                           model.type = "cfa"
                           )
summary(fit.test)
```

Trying different method:
```{r}
fit.test.fixed <- lavaan::lavaan(model, testHS,
                                 auto.fix.first = TRUE, auto.var = TRUE,
                                 do.fit = FALSE, start = fit.train
                                 )
summary(fit.test.fixed)

lavaan:::lav_model_fit(model, testHS)
```

Using parameter estimates found in train set to define model to be fitted in the test set:
```{r}
# Does fixing parameters actually work? Lets check the output
fixed.model <- " visual =~ 3*x1 + 4*x2 + 5*x3 
                 x1 ~~ 0.5*x1 "
fit.fixed.model <- lavaan::cfa(fixed.model, trainHS)
summary(fit.fixed.model)
```

Yes, fixing parameters works.
Idea: to use the output of partable to completely define the model which can be fitted on the test set.
```{r}
fit.train <- lavaan::cfa(model, trainHS)

train.partable <- partable(fit.train)

head(train.partable)

train.partable <- train.partable %>% 
  select(lhs, op, rhs, est)

## Making updated model:

# Trying with 1 line first:

# Obtaining the RHS (estimate * variable):
line1rhs <- paste(train.partable[1, 4], train.partable[1, 3], sep = "*")

# Obtaining the LHS and operator:
line1lhsop <- paste(train.partable[1, 1], train.partable[1, 2])

# Combining the two:
line1 <- paste(line1lhsop, line1rhs, sep = " ")

line1 # So, this works.
```

Next, let me try automating this...
```{r}
# vector to save outputs in:
lhs <- rep(0, nrow(train.partable))
rhs <- rep(0, nrow(train.partable))
line <- rep(0, nrow(train.partable))

for (i in 1:nrow(train.partable)) {
  lhs[i] <- paste(train.partable[i, 1], train.partable[i, 2])
  rhs[i] <- paste(train.partable[i, 4], train.partable[i, 3], sep = "*")
  line <- paste(lhs, rhs, sep = " ")
  
  # ff.model <- paste(line, collapse = " ")
  
  # for (i in 1:nrow(train.partable)) {
  #   fix.model <- c(line[i], sep = "\n ")
  # }
  
  # Trying manually:
  ff.model <- paste(line[2], line[3], line[4], line[5], line[6], line[8], line[9], line[10], line[11], line[12], line[13], line[14], line[15], sep = "\n ")
}

ff.model

lavaan::cfa(ff.model, trainHS)
semPaths(lavaan::cfa(ff.model, HolzingerSwineford1939), "est")

# summary(lavaan::cfa(model, testHS))
```
Conclusion: when all parameters are fixed, no fit is found. Huilen.



Another attempt:
```{r}
# Object to save parameters in:
mod <- data.frame(matrix(ncol = 4, nrow = nrow(train.partable)))
  #rep(0, nrow(train.partable))

# Obtaining each parameter estimate:
for (i in 1:nrow(train.partable)) {
  mod[i, 1] <- paste(train.partable[i, 1])
  mod[i, 2] <- paste(train.partable[i, 2])
  mod[i, 3] <- paste(train.partable[i, 3])
  mod[i, 4] <- paste(train.partable[i, 4])
}

head(mod)



# Making a model object:
fixed.model <- paste(mod)
```










